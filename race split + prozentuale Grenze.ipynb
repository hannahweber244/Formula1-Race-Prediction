{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157755, 19)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('formula1_daten.csv', sep = ';', decimal = '.')\n",
    "del df['Unnamed: 0']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufteilen des Datensatzes nach einzelnen Rennen und verkürzen der Datensätze nach prozentualem Rennfortschritt, zusätzlich wird eine Spalte hinzugefügt, die pro Runde die kumulierten Millisekunden enthält"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary enthält einzelne datensätze zu jedem rennen\n",
    "split_by_race = {}\n",
    "#grenzwert ab dem vorhersage über rennausgang gemacht werden soll (orientiert sich an race_completion)\n",
    "border = 0.4\n",
    "#dictionary, welches renndatensätze nur bis zu einem gewissen zeitpunkt enthält (zp wird nach border gewählt)\n",
    "sliced_races = {}\n",
    "\n",
    "for rid in df['raceId'].unique():\n",
    "    race = df.where(df.raceId == rid).dropna(how = 'all')\n",
    "    race.reset_index(inplace = True, drop = True)\n",
    "    split_by_race[rid] = race\n",
    "    \n",
    "    #finden der lap_number wo race_completion die angegebene border überschreitet\n",
    "    last_lap_num = race.where(race.race_completion == min(race.where(race.race_completion >= border).dropna(how = 'all')['race_completion'])).dropna(how = 'all')['lap_number'].unique()[0]\n",
    "    \n",
    "    #es werden nur daten aus race genommen, die bis zu dieser lap_number gehen\n",
    "    race_shortened = race.where(race.lap_number < last_lap_num).dropna(how = 'all')\n",
    "    race_shortened.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #hinzufügen einer spalte die die insgesamt gefahrenen millisekunden enthält\n",
    "    bis zu dieser Runde pro Fahrer enthält\n",
    "    race_shortened['sum_milliseconds_pro_lap'] = 0\n",
    "    \n",
    "    for did in race_shortened.driverId.unique():\n",
    "        for lapnum in race_shortened.lap_number.unique():\n",
    "            sum_ms = np.sum(race_shortened.where(np.logical_and(race_shortened.driverId == did,race_shortened.lap_number<=lapnum)).dropna(how = 'all')['lap_in_milliseconds'])\n",
    "            \n",
    "            #setzen der bisher gefahrenen Zeit (kumuliert) pro Fahrer und Runde\n",
    "            race_shortened.loc[race_shortened.where(np.logical_and(race_shortened.driverId == did,race_shortened.lap_number==lapnum)).dropna(how = 'all').index,'sum_milliseconds_pro_lap'] = sum_ms\n",
    "    \n",
    "    sliced_races[rid] = race_shortened\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anlegen von Ordnern, in denen DataFrames abgespeichert werden, um Zelle oben nicht immer ausführen zu müssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sliced_data'):\n",
    "    os.makedirs('sliced_data')\n",
    "    \n",
    "if not os.path.exists('split_data'):\n",
    "    os.makedirs('split_data')\n",
    "\n",
    "for key, value in sliced_races.items():\n",
    "    name = 'sliced_data/sliced_'+str(int(key))+'.csv'\n",
    "    value.to_csv(name,sep = ';', decimal = '.')\n",
    "for key, value in split_by_race.items():\n",
    "    name = 'split_data/split_'+str(int(key))+'.csv'\n",
    "    value.to_csv(name,sep = ';', decimal = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laden der oben erzeugten DataFrames aus den erstellten Ordnern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('sliced_data'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/sliced_data'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    sliced_races = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('sliced_data/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('sliced_data/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        sliced_races[f] = df\n",
    "    print('Einlesen der sliced Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')\n",
    "    \n",
    "if os.path.exists('split_data'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/split_data'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    split_by_race = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        split_by_race[f] = df\n",
    "    print('Einlesen der split Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alle Daten werden in sliced_races, split_by_race gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.017241\n",
       "1      0.034483\n",
       "2      0.051724\n",
       "3      0.068966\n",
       "4      0.086207\n",
       "         ...   \n",
       "478    0.327586\n",
       "479    0.344828\n",
       "480    0.362069\n",
       "481    0.379310\n",
       "482    0.396552\n",
       "Name: race_completion, Length: 483, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_races[841]['race_completion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anhang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = split_by_race[841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setzen der prozentualen Grenze, ab der weiterer Verlauf des Rennens vorhergesagt werden soll\n",
    "border = 0.4\n",
    "\n",
    "for race in split_by_race.values():\n",
    "    \n",
    "    #finden der lap_number wo race_completion die angegebene border überschreitet\n",
    "    last_lap_num = race.where(race.race_completion == min(race.where(race.race_completion >= border).dropna(how = 'all')['race_completion'])).dropna(how = 'all')['lap_number'].unique()[0]\n",
    "    \n",
    "    #es werden nur daten aus race genommen, die bis zu dieser lap_number gehen\n",
    "    race_shortened = race.where(race.lap_number < last_lap_num).dropna(how = 'all')\n",
    "    race_shortened.reset_index(inplace = True, drop = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.where(temp.race_completion == min(temp.where(temp.race_completion >= 0.4).dropna(how = 'all')['race_completion'])).dropna(how = 'all')['lap_number'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
