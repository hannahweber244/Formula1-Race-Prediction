{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as sqldf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Einlesen und abspeichern:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filenames = []\n",
    "#auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "\n",
    "for filename in os.listdir(os.getcwd()+'/kaggle_data'):\n",
    "    typ = filename.split('.')[-1]\n",
    "    name = filename.split('.')[0]\n",
    "    if typ == 'csv':\n",
    "        csv_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Speichern aller CSV Dateinen im Dict \"all_dfs\" mit deren Namen als key\n",
    "all_dfs = {}\n",
    "#einlesen und abspeichern als dataframe aller dateien\n",
    "for file in csv_filenames:\n",
    "    #print(file) #Um anzuzeigen, welche Datei genau eingelesen wird\n",
    "    path = 'kaggle_data/'+file\n",
    "    try:\n",
    "        df = pd.read_csv(path, engine = 'python', sep = ',')\n",
    "    except Exception as e:\n",
    "        df = pd.read_csv(path, engine = 'c', sep = ',') #Da ein Null byte in qualifying und races enthalten ist,\n",
    "                                                        #kann die python Engine das so nicht verarbeiten\n",
    "        #print(e) #Gibt Error aus, der Entstanden ist\n",
    "    #print(df.head())\n",
    "    all_dfs[file] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mergen der Daten verschiedener Dateien**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zur Übersichtlichkeit übertragen der DFs in Distincte Variablen\n",
    "laps = all_dfs['lapTimes.csv']\n",
    "drivers = all_dfs['drivers.csv']\n",
    "races = all_dfs['races.csv']\n",
    "result = all_dfs['results.csv']\n",
    "constructor = all_dfs['constructors.csv']\n",
    "pits = all_dfs[\"pitStops.csv\"]\n",
    "status = all_dfs[\"status.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Relevante Dataframes werden zusammengemerged und nur Informationen über 'raceId','year', 'circuitId',\n",
    "'driverId','lap_number', 'lap_position', 'lap_in_milliseconds', werden behalten, um ein \n",
    "Übersichlicheres Dataframe zu generieren. Aufbau mithilfe von SQL recht variabel, welche Infos mitzunehmen sind \"\"\"\n",
    "\n",
    "\n",
    "merged_df = sqldf.sqldf(\"\"\"select \n",
    "            t1.raceId,\n",
    "            t1.year,\n",
    "            --t1.round as race_round_number,\n",
    "            t1.circuitId, \n",
    "            --t1.name as grandprix_name,\n",
    "            --t1.date,\n",
    "            --t1.time as race_time,\n",
    "            --t2.round as round_number,\n",
    "            t2.driverId,\n",
    "            t2.lap as lap_number,\n",
    "            t2.position as lap_position,\n",
    "            --t2.time as lap_time,\n",
    "            t2.milliseconds as lap_in_milliseconds,\n",
    "            --t2.driverRef,\n",
    "            --t2.number as driver_number,\n",
    "            --t2.code as driver_code,\n",
    "            --t2.forename,\n",
    "            --t2.surname,\n",
    "            t2.driver_fullname\n",
    "            --t2.dob as driver_dob,\n",
    "            --t2.nationality as driver_nationality\n",
    "            from \n",
    "            races t1 join (select \n",
    "                d1.*,\n",
    "                d2.driverRef,\n",
    "                d2.number,\n",
    "                d2.code,\n",
    "                d2.forename,\n",
    "                d2.surname,\n",
    "                d2.forename||' '||d2.surname as driver_fullname,\n",
    "                d2.dob,\n",
    "                d2.nationality\n",
    "               -- d2.url\n",
    "                from laps d1 join drivers d2\n",
    "                on d1.driverId=d2.driverId) t2\n",
    "            on t1.raceId=t2.raceId\n",
    "            order by t1.raceId\n",
    "            \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output der obrigen Zelle:\n",
    "DataFrame mit folgenden Informationen:\n",
    "    1) raceId              --kann jedes gafahrene Rennen eindeutig identifizieren\n",
    "    2) year                --enthält das Jahr, in dem das Rennen gefahren wurde\n",
    "    3) circuitId           --Streckennummer (eindeutige ID)\n",
    "    4) driverId            --IDs der Fahrer\n",
    "    5) lap_number          --Rundennummer (pro Runde im DataFrame ein Eintrag)\n",
    "    6) lap_position        --Position des Fahrers in der aktuell gefahrenen Runde\n",
    "    7) lap_in_milliseconds --Dauer, die der Fahrer für die eine Runde gebraucht hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hinzufügen der constuctorId (=Eindeutige Kennzeichnung eines Teams) und der späteren Endposition\n",
    "merged_with_conpos = pd.merge(merged_df,result[['raceId', 'driverId','position', 'constructorId']], on=['raceId','driverId']) \n",
    "merged_with_conpos.rename(columns = {'position':'podium_position'}, inplace = True)  #Rename für Eindeutigere Bezeichnung "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pitstops**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Information hinzufügen, in welcher Runde ein Fahrer gestoppt hat\n",
    "pits[\"stop_binary\"] = 1 #Neue Spalte erstellen, die angbit, ob ein Fahrer in einer bestimmten Runde gestoppt hat (Box)\n",
    "pits.rename(columns = {\"lap\": \"lap_number\"}, inplace = True) #Rename der Spalte lap in der Pits Tabelle zu lap_number um merge leichter durchzuführen\n",
    "#Merge Durchführen, um auch Pits in merged_with_conpos zu bekommen\n",
    "merged_with_conpos = pd.merge(merged_with_conpos, pits[['raceId', 'driverId', 'lap_number', 'stop_binary']], on = ['raceId','driverId', 'lap_number'], how = \"outer\")\n",
    "#Nur die Rennen, ab 2011 beachten, wegen großer Umstellungen im Regelwerk (z.B. darf nichtmehr getankt werden und Einführung DRS)\n",
    "fin_newage = merged_with_conpos.where(merged_with_conpos.year >= 2011).dropna(how = \"all\") \n",
    "fin_newage[\"stop_binary\"] = fin_newage[\"stop_binary\"].replace(np.nan, 0) #Nans ersetzen\n",
    "#fin_newage.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Runden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Herausfinden der Rundenanzahl, die pro Rennen gefahren werden muss und in DF zwischenspeichern\n",
    "Max_rounds = sqldf.sqldf(\"\"\"\n",
    "                            select *, max(lap_number) as total_laps\n",
    "                            from fin_newage group by raceId \"\"\")\n",
    "\n",
    "#Mergen des eben erstellten DFs mit der Maximalen Rundenanzahl und dem aktuellen DF\n",
    "fin_newage = pd.merge(fin_newage, Max_rounds[['raceId', 'total_laps']], on ='raceId', how = \"outer\")\n",
    "\n",
    "#Berechen zu wie viel % ein Fahrer in einer gewissen Runde das Rennen schon hinter sich gebracht hat \n",
    "#Annahme: Jedes Rennen wird über die volle Distanz gefahren\n",
    "fin_newage[\"race_completion\"] = fin_newage[\"lap_number\"]/fin_newage[\"total_laps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Den staus aus der .csv Datei mit dem Status herausnehmen und identifizieren\n",
    "status = pd.merge(result, status[['statusId','status']], on ='statusId', how = \"outer\")\n",
    "status_df = sqldf.sqldf(\"\"\" select * from status where raceId >= 841\"\"\") #Weil nur Rennen ab 2011 in beatracht gezogen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anlegen einer temporären Spalte, die anzahl der überrundeten Runden enthält, bzw. sinnfrei zerschnittene strings\n",
    "status_df[\"count_laps\"] = status_df[\"status\"].apply(lambda y: y.split()[0][1:])\n",
    "\n",
    "def conv_int(x):\n",
    "    #konvertieren des eintrags in den typ integer, um später vergleich vornehmen zu können\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        #fall kommt nur vor wenn keine überrundung stattgefunden hat, also im generellen DNF fall oder Finished\n",
    "        x = 1000\n",
    "        \n",
    "    return x\n",
    "#anwenden der conv_int funktion auf die zuvor erzeugte temp spalte\n",
    "status_df[\"count_laps\"] = status_df.count_laps.apply(lambda y: conv_int(y))       \n",
    "\n",
    "#hinzufügen der spalte sttatus_clean, mit nur drei Merkmalsausprägungen Finished, lapped und DNF\n",
    "status_df[\"status_clean\"] = ['No_DNF' if status_df.at[v,\"status\"] == 'Finished' else 'No_DNF' if (status_df.at[v,\"status\"].startswith('+') and status_df.at[v,\"count_laps\"] <= 3)else 'DNF' for v in range(len(status_df.status))]\n",
    "\n",
    "#zusammenführen von status_df informationen und bisherigem dataframe\n",
    "fin_newage = pd.merge(fin_newage, status_df[['raceId', 'driverId', 'grid', 'status_clean', 'count_laps']], on = ['raceId', 'driverId'])\n",
    "\n",
    "\n",
    "#Status nur noch Binär Darstellen: 1 = No_DNF, 0 = DNF  --> Rest nutzlose Information\n",
    "fin_newage['status_binary'] = [1 if fin_newage.at[v,'status_clean']== 'No_DNF' else 0 for v in range(len(fin_newage.status_clean))]\n",
    "fin_newage.where(fin_newage.status_clean == 'DNF').dropna(how = 'all')\n",
    "test = fin_newage.replace(np.nan, 'lul')\n",
    "filt1 = test.podium_position != 'lul'\n",
    "filt2 = test.status_clean == 'DNF'\n",
    "#test.where(filt1 & filt2).dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total_minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generieren eines Temporären DFs, um die gesamt gefahrenen ms pro Fahrer pro Rennen zu berechnen\n",
    "t = sqldf.sqldf(\"\"\"select *, sum(lap_in_milliseconds) as total_milliseconds_temp\n",
    "                from fin_newage\n",
    "                group by raceId, driverId\"\"\")\n",
    "\n",
    "t['total_milliseconds'] = [t.at[x, 'total_milliseconds_temp'] if t.at[x,'count_laps'] == 1000 else t.at[x, 'total_milliseconds_temp']+(t.at[x, 'total_milliseconds_temp']/(t.at[x, 'total_laps']- t.at[x, 'count_laps']))*t.at[x, 'count_laps'] for x in range(len(t))]\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Informationen Entsprechend zusammenführen und zwischenvariable rausschmeißen\n",
    "fin_newage = pd.merge(fin_newage, t[['raceId', 'driverId', 'total_milliseconds']], on = ['raceId', 'driverId'], how = 'outer')\n",
    "fin_newage[\"total_minutes\"] = fin_newage['total_milliseconds']/60000  #ms in m umrechnen\n",
    "del fin_newage[\"total_milliseconds\"]\n",
    "del fin_newage[\"count_laps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regenrennen identifizieren**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Da Information über Regenrennen nicht bekannt sind im Datensatz, muss der Datensatz erweitert werden\n",
    "#1 bei Regen 0 bei nicht Regen\n",
    "fin_newage['rain'] = 0\n",
    "for i in range(len(fin_newage)):\n",
    "    if fin_newage.loc[i,'raceId'] in [847,861,879,910,914,934,942,953,957,967,950,982]:\n",
    "        fin_newage.loc[i,\"rain\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Berechnen der Form für jeden Fahrer**\n",
    "Form gibt eine Aussage darüber, wie gut der Fahrer in den vorherigen 3 Rennen der Saison abgeschnitten hat, desto geringer die Form des Fahreres, desto wahrscheinlicher ist es, dass ein Fahrer auch im nächsten Rennen gut abschneidet. Bei DNF wird für dieses Rennen die Startposition genommen +3 Plätze zusätzlich als Strafe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years = fin_newage.year.tolist()\n",
    "years = set(years) #Unique\n",
    "form_df = pd.DataFrame(columns = [\"raceId\", \"driverId\", \"form\"])\n",
    "letzter_platz = pd.DataFrame(columns = [\"year\", \"letzter_nummer\"])\n",
    "a = 0\n",
    "\n",
    "for year in years:\n",
    "    #filtern nach einem speziellen Jahr\n",
    "    temp_df = fin_newage.where(fin_newage.year == year).dropna(how = \"all\")\n",
    "    #auslesen aller Teams *2 = Anzahl der Rennteilnehmer, also schlechteste Rennposition\n",
    "    constructor_count = len(sqldf.sqldf(\"\"\"select distinct(constructorId)\n",
    "                                    from temp_df \n",
    "                                    group by constructorId\"\"\"))*2\n",
    "    #zwischenspeichern der constructor count informationen\n",
    "    zeile = pd.DataFrame(columns = letzter_platz.columns)\n",
    "    zeile.loc[0, :] = [year, constructor_count]\n",
    "    letzter_platz = letzter_platz.append(zeile)\n",
    "    temp_drivers = set(temp_df.driverId.tolist())\n",
    "    for driver in temp_drivers:\n",
    "        #filtern nach einem speziellen Fahrer\n",
    "        temp_df2 = temp_df.where(temp_df.driverId == driver).dropna(how = \"all\")\n",
    "        temp_df2 = sqldf.sqldf(\"\"\"select raceId, driverId, podium_position,status_clean, grid from temp_df2 group by raceId order by raceId\"\"\")\n",
    "        status = list(temp_df2['status_clean'])\n",
    "        if 'DNF'in status:\n",
    "            #wenn DNF in Rennen wird podiums position auf grid +3 gesetzt\n",
    "            temp_df2['podium_position'] = [temp_df2.at[v, 'podium_position'] if temp_df2.at[v,'status_clean'] == 'No_DNF' else (temp_df2.at[v,'grid']+3) for v in range(len(temp_df2))]\n",
    "            \n",
    "        #Ersetzen der Rennen in denen DNF, also NaN mit letztem Platz constructor_count\n",
    "        #temp_df2.replace(np.nan, constructor_count, inplace = True)\n",
    "        \n",
    "        #liste mit allen rennids wird erzeugt, um zu überprüfen ob welche in Abschnitt fehlen\n",
    "        start_race_id =  temp_df2.at[0, \"raceId\"]\n",
    "        end_race_id = temp_df2.at[list(temp_df2.index)[-1], \"raceId\"]\n",
    "        r_ids = [x for x in range(int(start_race_id), int(end_race_id)+1)]\n",
    "        temp_ids = temp_df2.raceId.astype(int)\n",
    "        temp_ids = temp_ids.values.tolist()\n",
    "        \n",
    "        #überprüfen ob alle raceIds in der Liste vorhanden sind\n",
    "        if temp_ids != r_ids:\n",
    "            #fehlende rennen werden in liste gespeichert\n",
    "            missing = [x for x in r_ids if x not in temp_ids]\n",
    "            \n",
    "            for miss in missing:\n",
    "                #einfügen der fehlenden raceids in den dataframe\n",
    "                platzhalter = pd.DataFrame(columns = temp_df2[['raceId','driverId','podium_position']].columns)\n",
    "                #dataframe an stelle wo id fehlt aufteilen in vorher und nachher\n",
    "                vorher = temp_df2.where(temp_df2.raceId < miss).dropna(how = \"all\")\n",
    "                nachher = temp_df2.where(temp_df2.raceId > miss).dropna(how = \"all\")\n",
    "                #erzeugen einer neuen Reihe, die fehlende id, driverId und als pp den letztmöglichen Platz enthält\n",
    "                d = vorher.at[list(vorher.index)[0], \"driverId\"]\n",
    "                platzhalter.loc[0,:] = [miss, d, constructor_count]\n",
    "                vorher = vorher.append(platzhalter)\n",
    "                temp_df2 = vorher.append(nachher)\n",
    "                temp_df2.reset_index(inplace = True, drop = True)\n",
    "                \n",
    "        for i, row in temp_df2.iterrows():\n",
    "            #form des fahrers anhand seiner podiums positionen der in der saison vorhergegangenen rennen bestimmen\n",
    "            #Tatsächliche berechnung\n",
    "            raceId = row[\"raceId\"]\n",
    "            driverId = row[\"driverId\"]\n",
    "            #i = 4\n",
    "            if i == 0:\n",
    "                form = 0\n",
    "            elif i < 4:\n",
    "                zaehler = temp_df2.loc[:i-1,\"podium_position\"].tolist()\n",
    "                form = np.sum(zaehler)/i\n",
    "            else:\n",
    "                zaehler = temp_df2.loc[i-4:i-1,\"podium_position\"].tolist()\n",
    "                form = np.sum(zaehler)/4\n",
    "                \n",
    "            form_df.loc[a, :] = [raceId, driverId, form]\n",
    "            #print(\"form df\", form_df)\n",
    "            a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information über den Status in Fin_newage bringen \n",
    "final_df = pd.merge(fin_newage, form_df, on = [\"raceId\", \"driverId\"])\n",
    "final_df.form = final_df.form.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "global letzter_platz\n",
    "#ersetzen von nan in der podiums position mit dem letzten platz aus dem jeweiligen jahr (NICHT ZUR FORMBERECHNUNG)\n",
    "def apply_pp (row):\n",
    "    global letzter_platz\n",
    "    pp = row[\"podium_position\"]\n",
    "    year = row[\"year\"]\n",
    "    if np.isnan(pp):\n",
    "        df_ = letzter_platz.where(letzter_platz.year == year).dropna(how = \"all\")\n",
    "        pp_neu = df_.loc[list(df_.index)[0],\"letzter_nummer\"]\n",
    "        return pp_neu\n",
    "    else:\n",
    "        return pp\n",
    "#ersetzen der NaN in podium position, wegen DNF, durch letzten Platz in dem betroffenen Rennen\n",
    "#Aufruf der obrigen Fkt\n",
    "final_df[\"podium_position\"] = final_df.apply(apply_pp, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['raceId', 'year', 'circuitId', 'driverId', 'lap_number', 'lap_position',\n",
       "       'lap_in_milliseconds', 'driver_fullname', 'podium_position',\n",
       "       'constructorId', 'stop_binary', 'total_laps', 'race_completion', 'grid',\n",
       "       'status_clean', 'status_binary', 'total_minutes', 'rain', 'form'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nur das mitnehmen was auch gebraucht wird**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nur die Columns mitnehmen, die später gebraucht werden\n",
    "df = pd.DataFrame()\n",
    "df = final_df[['raceId','driverId','driver_fullname','year','podium_position','lap_in_milliseconds','status_clean','status_binary','lap_number','circuitId','lap_position','constructorId','stop_binary','race_completion','grid','form','rain','total_minutes']]\n",
    "df['bias'] = 1 #Bias hinzufügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummie Variablen erstellen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aus circuitId und constructorId Dummie Variablen machen, da diese Nominal sind\n",
    "#Vor slicing, da beispielsweise nicht alle Teams in jedem Jahr mitgefahren sind,\n",
    "#aber beispielsweise ein NN immer die selbe Input Size braucht\n",
    "df = pd.get_dummies(df, columns=['circuitId', 'constructorId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**slicing auf 50% jedes einzelne Rennen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary soll einzelne datensätze zu jedem rennen enthalten\n",
    "split_by_race = {}\n",
    "#grenzwert ab dem vorhersage über rennausgang gemacht werden soll (orientiert sich an race_completion)\n",
    "border = 0.5 #nach 50% des Rennens soll der Ausgang vorhergesagt werden\n",
    "#dictionary, welches renndatensätze nur bis zu einem gewissen zeitpunkt enthält (zp wird nach border gewählt)\n",
    "sliced_races = {}\n",
    "\n",
    "for rid in df['raceId'].unique():\n",
    "    race = df.where(df.raceId == rid).dropna(how = 'all')\n",
    "    race.reset_index(inplace = True, drop = True)\n",
    "    split_by_race[rid] = race\n",
    "    \n",
    "    #finden der lap_number wo race_completion die angegebene border überschreitet\n",
    "    last_lap_num = race.where(race.race_completion == min(race.where(race.race_completion >= border).dropna(how = 'all')['race_completion'])).dropna(how = 'all')['lap_number'].unique()[0]\n",
    "    \n",
    "    #es werden nur daten aus race genommen, die bis zu dieser lap_number gehen\n",
    "    race_shortened = race.where(race.lap_number < last_lap_num).dropna(how = 'all')\n",
    "    race_shortened.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #hinzufügen einer spalte die die insgesamt gefahrenen millisekunden enthält bis zu dieser Runde pro Fahrer enthält\n",
    "    race_shortened['sum_milliseconds_pro_lap'] = 0\n",
    "    \n",
    "    for did in race_shortened.driverId.unique():\n",
    "        \n",
    "        l_lap_driver = race_shortened.where(race_shortened.driverId == did).dropna(how = 'all')['lap_number'].tail(1).reset_index()['lap_number'][0]\n",
    "        status_driver = race_shortened.status_clean.unique()[0]\n",
    "        if status_driver == 'DNF':\n",
    "            if l_lap_driver == last_lap_num-1:#der Fahrer ist das Rennen bis zu dieser Runde ohne DNF gefahren\n",
    "                idces = race_shortened.where(race_shortened.driverId == did).dropna(how = 'all').index\n",
    "                idces = list(idces)\n",
    "                idx1 = idces[0]\n",
    "                idx2 = idces[-1]\n",
    "                race_shortened.loc[idx1:idx2, 'status_clean'] = 'No_DNF' #DNF wird als No_DNF überschrieben, da bist zu dieser Runde kein DNF stattgefunden hat\n",
    "                race_shortened['status_binary'] = [1 if race_shortened.at[v,'status_clean']== 'No_DNF' else 0 for v in range(len(race_shortened.status_clean))]\n",
    "        for lapnum in race_shortened.lap_number.unique():\n",
    "            sum_ms = np.sum(race_shortened.where(np.logical_and(race_shortened.driverId == did,race_shortened.lap_number<=lapnum)).dropna(how = 'all')['lap_in_milliseconds'])\n",
    "            \n",
    "            #setzen der bisher gefahrenen Zeit (kumuliert) pro Fahrer und Runde\n",
    "            race_shortened.loc[race_shortened.where(np.logical_and(race_shortened.driverId == did,race_shortened.lap_number==lapnum)).dropna(how = 'all').index,'sum_milliseconds_pro_lap'] = sum_ms\n",
    "        race_shortened['sum_minutes_pro_lap'] = race_shortened['sum_milliseconds_pro_lap'] / 60000\n",
    "    \n",
    "    sliced_races[rid] = race_shortened\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufsummiere aller Boxenstops, die bis 50% des Rennens pro Fahrer gemacht wurden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sliced_races.keys():   #Geht alle Rennen im Dict durch\n",
    "    element = sliced_races[key]\n",
    "    stops = sqldf.sqldf(\"\"\"\n",
    "                            select *, sum(stop_binary) as sum_stops\n",
    "                            from element group by driverId \"\"\")            #Summiert stops auf, pro Fahrer\n",
    "    sliced_races[key] = pd.merge(sliced_races[key], stops[['driverId', 'sum_stops']], on ='driverId', how = \"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finale Auswahl der notwendigen Variablen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rauswerfen nicht relevanter Daten und alles auf 1 Dimension bringen\n",
    "for key in sliced_races.keys():\n",
    "    try:\n",
    "        del sliced_races[key]['status_binär']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del sliced_races[key]['status_clean']\n",
    "        del sliced_races[key]['lap_number']\n",
    "        del sliced_races[key]['sum_milliseconds_pro_lap']\n",
    "        del sliced_races[key]['stop_binary']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        sliced_races[key]['sum_stops'] = sliced_races[key]['sum_stops_x']\n",
    "        del sliced_races[key]['sum_stops_x']\n",
    "        del sliced_races[key]['sum_stops_y']\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speichern der Erstellten Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sliced_data'):\n",
    "    os.makedirs('sliced_data')\n",
    "\n",
    "\n",
    "for key, value in sliced_races.items():\n",
    "    name = 'sliced_data/sliced_'+str(int(key))+'.csv'\n",
    "    value.to_csv(name,sep = ';', decimal = '.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ende der Datenaufbereitung**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
