{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as sqldf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys,os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_top (column, df, feat_count = 10):\n",
    "    '''\n",
    "    hot one encoding, limitiert auf die feat_count häufigsten features\n",
    "    eines nominalen features um zu Hohe dimensionen zu vermeiden\n",
    "    \n",
    "    column: liste mit einem oder mehr Spaltennamen, die hot encoded werden sollen\n",
    "    df: dataframe der die Datenbasis darstellt\n",
    "    feat_count: Anzahl Spalten die für jede Spalte encoded werden\n",
    "    '''\n",
    "    df_ = df.copy(deep = True)\n",
    "    \n",
    "    for col in column:\n",
    "        \n",
    "        \n",
    "        #nur die häufigsten feat_count Featues werden encoded\n",
    "        encode_features = [x for x in df_[col].value_counts(ascending = False).head(feat_count).index]\n",
    "        if col == 'status_clean':\n",
    "            #encode_features = ['lapped', 'Finished', 'DNF']\n",
    "            encode_features = ['Finished', 'DNF']\n",
    "        for feature in encode_features:\n",
    "            col_feature = col + '_'+str(feature)\n",
    "            \n",
    "            #dort wo feature nicht dem encode feature entspricht wird eine 0 gesetzt\n",
    "            df_[col_feature] = df_.where(df_[col] == feature, other = 0)[col]\n",
    "            #encode feature selbst wird in dataframe durch eine 1 ersetzt\n",
    "            df_[col_feature].replace(feature, 1, inplace = True)\n",
    "            \n",
    "        \n",
    "        #löschen der nun \"bereinigten\" Spalte\n",
    "        del df_[col]\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einlesen der sliced Dateien erfolgreich\n",
      "Einlesen der split Dateien erfolgreich\n"
     ]
    }
   ],
   "source": [
    "rain_id = [847,861,879,910,914,934,942,953,957,967,970,982]\n",
    "if os.path.exists('sliced_data70'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/sliced_data70'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    sliced_races = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('sliced_data70/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('sliced_data70/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        df[\"rain\"] = 0\n",
    "        if list(df[\"raceId\"])[0] in rain_id:\n",
    "            df[\"rain\"] = 1\n",
    "        sliced_races[f] = df\n",
    "    print('Einlesen der sliced Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')\n",
    "    \n",
    "if os.path.exists('split_data'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/split_data'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    split_by_race = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        split_by_race[f] = df\n",
    "    print('Einlesen der split Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---shuffle races---\n",
      "---training---\n",
      "mse: 17.299965468326885\n",
      "mae: 2.475987786306369\n",
      "---testing---\n",
      "mse: 8.528937382485418\n",
      "mae: 1.9438280411415028\n"
     ]
    }
   ],
   "source": [
    "print('---shuffle races---')\n",
    "keys = list(sliced_races.keys())\n",
    "random.shuffle(keys)\n",
    "sliced_shuffled = {}\n",
    "for key in keys:\n",
    "    sliced_shuffled[key] = sliced_races[key]\n",
    "\n",
    "\n",
    "#columns werden definiert, die erst einmal nicht beachtet werden sollen\n",
    "nogo_columns = [#'grid',\n",
    "                #'race_completion',\n",
    "                'lap_position','circuitId','lap_number',\n",
    "                'podium_position', 'raceId',\n",
    "                'grandprix_name', 'driver_fullname',\n",
    "               'constructor_name', 'total_laps',\n",
    "               'status_clean', 'constructorId',\n",
    "                'total_milliseconds', 'driverId'\n",
    "               'lap_in_milliseconds','year', 'stop_binary']\n",
    "\n",
    "#definieren eines linearen Regressionsmodells\n",
    "reg = LinearRegression()\n",
    "\n",
    "train_break = 120\n",
    "category_count = 13\n",
    "counter = 0\n",
    "\n",
    "print('---training---')\n",
    "full_races = pd.DataFrame()\n",
    "for raceId, race in sliced_shuffled.items():\n",
    "    full = pd.DataFrame(columns = race.columns)\n",
    "    if counter == train_break:\n",
    "        break\n",
    "    else:\n",
    "        last_lap = max(race.lap_number.tolist())\n",
    "        for did in race.driverId.unique():\n",
    "            stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "            race['stop_sum'] = stop_sum\n",
    "            driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "            full = full.append(driver_df)\n",
    "        #for elem in full['driverId'].unique():\n",
    "        #    full[str(elem)] = full['driverId'] == elem\n",
    "        #for elem in full['constructorId'].unique():\n",
    "        #    full[str(elem)] = full['constructorId'] == elem\n",
    "        #for c in ['driverId','constructorId']:\n",
    "        #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "        #temp.replace(np.nan,0,inplace = True)\n",
    "        #full = temp.copy(deep = True)\n",
    "        ##for col in temp.columns:\n",
    "        #    full[col] = temp[col]\n",
    "        full_races = full_races.append(full)\n",
    "#full_races = full_races.replace(np.nan,0)   \n",
    "#full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "\n",
    "#umrechnen in minuten\n",
    "y = np.array(full_races['total_milliseconds']/60000)\n",
    "races = full_races[cols]  \n",
    "#races = races.dropna(how = 'any')\n",
    "X = np.array(races)\n",
    "reg = reg.fit(X, y)\n",
    "A = reg.predict(X)\n",
    "mse = mean_squared_error(A, y)\n",
    "mae = MAE(A,y)\n",
    "print('mse:', mse)\n",
    "print('mae:',mae)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "full_races = pd.DataFrame()\n",
    "print('---testing---')\n",
    "for raceId, race in sliced_shuffled.items():\n",
    "    full = pd.DataFrame(columns = race.columns)\n",
    "    if counter == train_break:\n",
    "        last_lap = max(race.lap_number.tolist())\n",
    "        for did in race.driverId.unique():\n",
    "            stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "            race['stop_sum'] = stop_sum\n",
    "            driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "            full = full.append(driver_df)\n",
    "            \n",
    "        #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "        #temp.replace(np.nan,0,inplace = True)\n",
    "        #full = temp.copy(deep = True)\n",
    "        #for col in temp.columns:\n",
    "        #    full[col] = temp[col]\n",
    "        #full = hot_encode_top(['status_clean'],full)\n",
    "        #full = hot_encode_top(['status_clean','driverId', 'constructorId'],full)\n",
    "        full_races = full_races.append(full)\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "#full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "full_races = full_races.replace(np.nan,0)   \n",
    "y = np.array(full_races['total_milliseconds']/60000)\n",
    "cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "races = full_races[cols]  \n",
    "X = np.array(races)\n",
    "A = reg.predict(X)\n",
    "mse = mean_squared_error(A, y)\n",
    "mae = MAE(A,y)\n",
    "print('mse:', mse)\n",
    "print('mae:',mae)\n",
    "\n",
    "#hinzufügen der 'wichtigen' spalten zur späteren auswertung der vorhersagen auf dem trainingsdatensatz\n",
    "full_races['prediction'] = A\n",
    "full_races['total_milliseconds'] = y\n",
    "full_races['total_minutes'] = y/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner, second, third: Sebastian Vettel , Mark Webber , Fernando Alonso\n",
      "predicted winner: Paul di Resta \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Valtteri Bottas\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Nico Rosberg , Max Verstappen , Lewis Hamilton\n",
      "predicted winner: Max Verstappen \n",
      "\n",
      "winner, second, third: Kimi RÃŒ_ikkÃŒÂ¦nen , Fernando Alonso , Sebastian Vettel\n",
      "predicted winner: Kimi RÃŒ_ikkÃŒÂ¦nen \n",
      "\n",
      "winner, second, third: Nico Rosberg , Kevin Magnussen , Jenson Button\n",
      "predicted winner: Daniel Ricciardo \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Fernando Alonso , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Mark Webber \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Mark Webber , Nico Rosberg\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Jenson Button , Fernando Alonso\n",
      "predicted winner: Bruno Senna \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Fernando Alonso , Mark Webber\n",
      "predicted winner: Mark Webber \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Felipe Massa , Valtteri Bottas\n",
      "predicted winner: Kamui Kobayashi \n",
      "\n",
      "winner, second, third: Mark Webber , Fernando Alonso , Sebastian Vettel\n",
      "predicted winner: Fernando Alonso \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Daniel Ricciardo\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Sebastian Vettel , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Valtteri Bottas \n",
      "\n",
      "winner, second, third: Daniel Ricciardo , Nico Rosberg , Sebastian Vettel\n",
      "predicted winner: Sergio PÃŒÂ©rez \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Lewis Hamilton , Mark Webber\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Jenson Button , Sebastian Vettel , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Jenson Button \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Mark Webber , Lewis Hamilton\n",
      "predicted winner: Daniel Ricciardo \n",
      "\n",
      "genaue treffer: 5\n",
      "nah dran: 4\n",
      "weiter weg: 1\n"
     ]
    }
   ],
   "source": [
    "treffer = 0\n",
    "nahdran = 0\n",
    "weiterweg = 0\n",
    "for raceId in full_races.raceId.unique():\n",
    "    \n",
    "    race = full_races.where(full_races.raceId == raceId).dropna(how = 'all')\n",
    "    winner = race.where(race.podium_position == 1).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    second = race.where(race.podium_position == 2).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    third = race.where(race.podium_position == 3).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    fourth = race.where(race.podium_position == 4).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    fifth = race.where(race.podium_position == 5).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    sixth = race.where(race.podium_position == 6).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    seventh = race.where(race.podium_position == 7).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    pred_winner = race.where(race.prediction == min(race.prediction)).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    podium = [second,third]\n",
    "    seven = [fourth,fifth,sixth,seventh]\n",
    "    if pred_winner == winner:\n",
    "        treffer += 1\n",
    "    if pred_winner in podium:\n",
    "        nahdran += 1\n",
    "    if pred_winner in seven:\n",
    "        weiterweg += 1\n",
    "    print('winner, second, third:', winner,',' ,second,',' , third)\n",
    "    print('predicted winner:', pred_winner,'\\n')\n",
    "    \n",
    "print('genaue treffer:', treffer)\n",
    "print('nah dran:', nahdran)\n",
    "print('weiter weg:', weiterweg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---shuffle races---\n",
      "---training---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hwebe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.32636e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 17.29996546832689\n",
      "mae: 2.4759877864118836\n",
      "---testing---\n",
      "mse: 13.463522842807729\n",
      "mae: 2.351277978922402\n",
      "alpha: 0\n",
      "====================\n",
      "---training---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hwebe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.6622e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 17.394417571259474\n",
      "mae: 2.4663528914954687\n",
      "---testing---\n",
      "mse: 13.277933343544102\n",
      "mae: 2.276961391318\n",
      "alpha: 0.1\n",
      "====================\n",
      "---training---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hwebe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.99814e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 17.4495809022525\n",
      "mae: 2.471165797627999\n",
      "---testing---\n",
      "mse: 13.266364294961916\n",
      "mae: 2.267584161054838\n",
      "alpha: 0.2\n",
      "====================\n",
      "---training---\n",
      "mse: 17.479147980611017\n",
      "mae: 2.474222790432166\n",
      "---testing---\n",
      "mse: 13.266396065256343\n",
      "mae: 2.2648438960045154\n",
      "alpha: 0.3\n",
      "====================\n",
      "---training---\n",
      "mse: 17.49734478491083\n",
      "mae: 2.4762505598553997\n",
      "---testing---\n",
      "mse: 13.268143151374503\n",
      "mae: 2.2637635321260827\n",
      "alpha: 0.4\n",
      "====================\n",
      "---training---\n",
      "mse: 17.50964013535708\n",
      "mae: 2.477683072256026\n",
      "---testing---\n",
      "mse: 13.270096330656946\n",
      "mae: 2.2632869650883713\n",
      "alpha: 0.5\n",
      "====================\n",
      "---training---\n",
      "mse: 17.51850190687774\n",
      "mae: 2.4787333551584485\n",
      "---testing---\n",
      "mse: 13.27195732718757\n",
      "mae: 2.2630616342236882\n",
      "alpha: 0.6\n",
      "====================\n",
      "---training---\n",
      "mse: 17.52519640490124\n",
      "mae: 2.4795340736273794\n",
      "---testing---\n",
      "mse: 13.27367724268673\n",
      "mae: 2.262986087139394\n",
      "alpha: 0.7\n",
      "====================\n",
      "---training---\n",
      "mse: 17.530437971239774\n",
      "mae: 2.4801653671752226\n",
      "---testing---\n",
      "mse: 13.27526516626893\n",
      "mae: 2.263030312797003\n",
      "alpha: 0.8\n",
      "====================\n",
      "---training---\n",
      "mse: 17.53465950345362\n",
      "mae: 2.480672561654685\n",
      "---testing---\n",
      "mse: 13.276741852808204\n",
      "mae: 2.2631304702005712\n",
      "alpha: 0.9\n",
      "====================\n",
      "---training---\n",
      "mse: 17.538138400373168\n",
      "mae: 2.4810934494952996\n",
      "---testing---\n",
      "mse: 13.278127732846192\n",
      "mae: 2.263275275247635\n",
      "alpha: 1\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "alphas = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "print('---shuffle races---')\n",
    "\n",
    "keys = list(sliced_races.keys())\n",
    "random.shuffle(keys)\n",
    "sliced_shuffled = {}\n",
    "for key in keys:\n",
    "    sliced_shuffled[key] = sliced_races[key]\n",
    "\n",
    "\n",
    "#columns werden definiert, die erst einmal nicht beachtet werden sollen\n",
    "nogo_columns = [#'grid',\n",
    "                #'race_completion',\n",
    "                'lap_position','circuitId','lap_number',\n",
    "                'podium_position', 'raceId',\n",
    "                'grandprix_name', 'driver_fullname',\n",
    "               'constructor_name', 'total_laps',\n",
    "               'status_clean', 'constructorId',\n",
    "                'total_milliseconds', 'driverId'\n",
    "               'lap_in_milliseconds','year', 'stop_binary']\n",
    "\n",
    "#testen verschiedener Generalisierungsstufen für das Regressionsmodell\n",
    "for alpha in alphas:\n",
    "\n",
    "    #definieren eines Ridge Regressionsmodells\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    train_break = 120\n",
    "    category_count = 13\n",
    "    counter = 0\n",
    "    \n",
    "    print('---training---')\n",
    "    full_races = pd.DataFrame()\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            break\n",
    "        else:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "            \n",
    "            full_races = full_races.append(full)\n",
    "    #full_races = full_races.replace(np.nan,0)   \n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    \n",
    "    #umrechnen in minuten\n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    races = full_races[cols]  \n",
    "    #races = races.dropna(how = 'any')\n",
    "    X = np.array(races)\n",
    "    ridge = ridge.fit(X, y)\n",
    "    A = ridge.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    full_races = pd.DataFrame()\n",
    "    print('---testing---')\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "                \n",
    "            #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "            #temp.replace(np.nan,0,inplace = True)\n",
    "            #full = temp.copy(deep = True)\n",
    "            #for col in temp.columns:\n",
    "            #    full[col] = temp[col]\n",
    "            #full = hot_encode_top(['status_clean'],full)\n",
    "            #full = hot_encode_top(['status_clean','driverId', 'constructorId'],full)\n",
    "            full_races = full_races.append(full)\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    full_races = full_races.replace(np.nan,0)   \n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    races = full_races[cols]  \n",
    "    X = np.array(races)\n",
    "    A = ridge.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    print('alpha:',alpha)\n",
    "    print('====================')\n",
    "    \n",
    "    #hinzufügen der 'wichtigen' spalten zur späteren auswertung der vorhersagen auf dem trainingsdatensatz\n",
    "    full_races['prediction'] = A\n",
    "    full_races['total_milliseconds'] = y\n",
    "    full_races['total_minutes'] = y/60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bestes alpha zeigt sich bei ungefähr 0.7, im folgenden werden zufällig alphas um den WErt 0.7 erzeugt, um zu sehen welches am besten funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---shuffle races---\n",
      "---training---\n",
      "mse: 17.52548853541353\n",
      "mae: 2.479569310329132\n",
      "---testing---\n",
      "mse: 12.646885322223724\n",
      "mae: 2.4798965104922854\n",
      "alpha: 0.705\n",
      "====================\n",
      "---training---\n",
      "mse: 17.525662123958107\n",
      "mae: 2.47959022730646\n",
      "---testing---\n",
      "mse: 12.647182076470711\n",
      "mae: 2.4799532386131125\n",
      "alpha: 0.708\n",
      "====================\n",
      "---training---\n",
      "mse: 17.5237431759634\n",
      "mae: 2.4793590527587077\n",
      "---testing---\n",
      "mse: 12.643921513329293\n",
      "mae: 2.4793270583134603\n",
      "alpha: 0.676\n",
      "====================\n",
      "---training---\n",
      "mse: 17.523429331016544\n",
      "mae: 2.4793214682734894\n",
      "---testing---\n",
      "mse: 12.643392227605966\n",
      "mae: 2.479224822458353\n",
      "alpha: 0.671\n",
      "====================\n",
      "---training---\n",
      "mse: 17.524298278885936\n",
      "mae: 2.479425565203147\n",
      "---testing---\n",
      "mse: 12.644860326293621\n",
      "mae: 2.4795079982200807\n",
      "alpha: 0.685\n",
      "====================\n",
      "---training---\n",
      "mse: 17.525078554773728\n",
      "mae: 2.47951984596137\n",
      "---testing---\n",
      "mse: 12.646185916163297\n",
      "mae: 2.4797626002953788\n",
      "alpha: 0.698\n",
      "====================\n",
      "---training---\n",
      "mse: 17.52435919248803\n",
      "mae: 2.479432891582909\n",
      "---testing---\n",
      "mse: 12.644963556877121\n",
      "mae: 2.479527862697628\n",
      "alpha: 0.686\n",
      "====================\n",
      "---training---\n",
      "mse: 17.52617544235263\n",
      "mae: 2.4796525391607434\n",
      "---testing---\n",
      "mse: 12.64806182434824\n",
      "mae: 2.4801210974131047\n",
      "alpha: 0.717\n",
      "====================\n",
      "---training---\n",
      "mse: 17.52656714334626\n",
      "mae: 2.4797000657504937\n",
      "---testing---\n",
      "mse: 12.648735422898088\n",
      "mae: 2.4802493002458594\n",
      "alpha: 0.724\n",
      "====================\n",
      "---training---\n",
      "mse: 17.525255115067367\n",
      "mae: 2.4795411588156493\n",
      "---testing---\n",
      "mse: 12.646486868686445\n",
      "mae: 2.479820257568121\n",
      "alpha: 0.701\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print('---shuffle races---')\n",
    "\n",
    "keys = list(sliced_races.keys())\n",
    "random.shuffle(keys)\n",
    "sliced_shuffled = {}\n",
    "for key in keys:\n",
    "    sliced_shuffled[key] = sliced_races[key]\n",
    "\n",
    "\n",
    "#columns werden definiert, die erst einmal nicht beachtet werden sollen\n",
    "nogo_columns = [#'grid',\n",
    "                #'race_completion',\n",
    "                'lap_position','circuitId','lap_number',\n",
    "                'podium_position', 'raceId',\n",
    "                'grandprix_name', 'driver_fullname',\n",
    "               'constructor_name', 'total_laps',\n",
    "               'status_clean', 'constructorId',\n",
    "                'total_milliseconds', 'driverId'\n",
    "               'lap_in_milliseconds','year', 'stop_binary']\n",
    "\n",
    "#testen verschiedener Generalisierungsstufen für das Regressionsmodell\n",
    "for i in range(10):\n",
    "    #random erzeugen eines alphas\n",
    "    \n",
    "    alpha = random.randint(668,730)\n",
    "    alpha = alpha/1000\n",
    "    #definieren eines Ridge Regressionsmodells\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    train_break = 120\n",
    "    category_count = 13\n",
    "    counter = 0\n",
    "    \n",
    "    print('---training---')\n",
    "    full_races = pd.DataFrame()\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            break\n",
    "        else:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "            \n",
    "            full_races = full_races.append(full)\n",
    "    #full_races = full_races.replace(np.nan,0)   \n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    \n",
    "    #umrechnen in minuten\n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    races = full_races[cols]  \n",
    "    #races = races.dropna(how = 'any')\n",
    "    X = np.array(races)\n",
    "    ridge = ridge.fit(X, y)\n",
    "    A = ridge.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    full_races = pd.DataFrame()\n",
    "    print('---testing---')\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "                \n",
    "            #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "            #temp.replace(np.nan,0,inplace = True)\n",
    "            #full = temp.copy(deep = True)\n",
    "            #for col in temp.columns:\n",
    "            #    full[col] = temp[col]\n",
    "            #full = hot_encode_top(['status_clean'],full)\n",
    "            #full = hot_encode_top(['status_clean','driverId', 'constructorId'],full)\n",
    "            full_races = full_races.append(full)\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    full_races = full_races.replace(np.nan,0)   \n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    races = full_races[cols]  \n",
    "    X = np.array(races)\n",
    "    A = ridge.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    print('alpha:',alpha)\n",
    "    print('====================')\n",
    "    \n",
    "    #hinzufügen der 'wichtigen' spalten zur späteren auswertung der vorhersagen auf dem trainingsdatensatz\n",
    "    full_races['prediction'] = A\n",
    "    full_races['total_milliseconds'] = y\n",
    "    full_races['total_minutes'] = y/60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphas werden jetzt nur zwischen 0.65 und 0.7 gewählt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---shuffle races---\n",
      "---training---\n",
      "mse: 17.524114627639907\n",
      "mae: 2.4794034739777855\n",
      "---testing---\n",
      "mse: 48.451973188113044\n",
      "mae: 3.3339561471586037\n",
      "alpha: 0.682\n",
      "====================\n",
      "---training---\n",
      "mse: 17.524601344696265\n",
      "mae: 2.4794621603785436\n",
      "---testing---\n",
      "mse: 48.45229221232572\n",
      "mae: 3.3341171915337933\n",
      "alpha: 0.69\n",
      "====================\n",
      "---training---\n",
      "mse: 17.522854299266765\n",
      "mae: 2.479252482218274\n",
      "---testing---\n",
      "mse: 48.451147846836555\n",
      "mae: 3.3335379463389883\n",
      "alpha: 0.662\n",
      "====================\n",
      "---training---\n",
      "mse: 17.524960128023157\n",
      "mae: 2.4795055414106444\n",
      "---testing---\n",
      "mse: 48.452527490550516\n",
      "mae: 3.3342357401846257\n",
      "alpha: 0.696\n",
      "====================\n",
      "---training---\n",
      "mse: 17.522918844448878\n",
      "mae: 2.4792602335353586\n",
      "---testing---\n",
      "mse: 48.45119008964011\n",
      "mae: 3.333559404816531\n",
      "alpha: 0.663\n",
      "====================\n",
      "---training---\n",
      "mse: 17.525019413744843\n",
      "mae: 2.4795127033342\n",
      "---testing---\n",
      "mse: 48.452566377325674\n",
      "mae: 3.3342553157176766\n",
      "alpha: 0.697\n",
      "====================\n",
      "---training---\n",
      "mse: 17.522265875637306\n",
      "mae: 2.4791822822368457\n",
      "---testing---\n",
      "mse: 48.45076286272057\n",
      "mae: 3.333342117925475\n",
      "alpha: 0.653\n",
      "====================\n",
      "---training---\n",
      "mse: 17.524900697068297\n",
      "mae: 2.479498360115012\n",
      "---testing---\n",
      "mse: 48.45248851114155\n",
      "mae: 3.3342161128282966\n",
      "alpha: 0.695\n",
      "====================\n",
      "---training---\n",
      "mse: 17.52206667617005\n",
      "mae: 2.479158527143035\n",
      "---testing---\n",
      "mse: 48.45063258206689\n",
      "mae: 3.3332757414156298\n",
      "alpha: 0.65\n",
      "====================\n",
      "---training---\n",
      "mse: 17.523867613351435\n",
      "mae: 2.479373941503999\n",
      "---testing---\n",
      "mse: 48.45181134352896\n",
      "mae: 3.333874317294214\n",
      "alpha: 0.678\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print('---shuffle races---')\n",
    "\n",
    "keys = list(sliced_races.keys())\n",
    "random.shuffle(keys)\n",
    "sliced_shuffled = {}\n",
    "for key in keys:\n",
    "    sliced_shuffled[key] = sliced_races[key]\n",
    "\n",
    "\n",
    "#columns werden definiert, die erst einmal nicht beachtet werden sollen\n",
    "nogo_columns = [#'grid',\n",
    "                #'race_completion',\n",
    "                'lap_position','circuitId','lap_number',\n",
    "                'podium_position', 'raceId',\n",
    "                'grandprix_name', 'driver_fullname',\n",
    "               'constructor_name', 'total_laps',\n",
    "               'status_clean', 'constructorId',\n",
    "                'total_milliseconds', 'driverId'\n",
    "               'lap_in_milliseconds','year', 'stop_binary']\n",
    "\n",
    "#testen verschiedener Generalisierungsstufen für das Regressionsmodell\n",
    "for i in range(10):\n",
    "    #random erzeugen eines alphas\n",
    "    \n",
    "    alpha = random.randint(650,700)\n",
    "    alpha = alpha/1000\n",
    "    #definieren eines Ridge Regressionsmodells\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    train_break = 120\n",
    "    category_count = 13\n",
    "    counter = 0\n",
    "    \n",
    "    print('---training---')\n",
    "    full_races = pd.DataFrame()\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            break\n",
    "        else:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "            \n",
    "            full_races = full_races.append(full)\n",
    "    #full_races = full_races.replace(np.nan,0)   \n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    \n",
    "    #umrechnen in minuten\n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    races = full_races[cols]  \n",
    "    #races = races.dropna(how = 'any')\n",
    "    X = np.array(races)\n",
    "    ridge = ridge.fit(X, y)\n",
    "    A = ridge.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    full_races = pd.DataFrame()\n",
    "    print('---testing---')\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "                \n",
    "            #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "            #temp.replace(np.nan,0,inplace = True)\n",
    "            #full = temp.copy(deep = True)\n",
    "            #for col in temp.columns:\n",
    "            #    full[col] = temp[col]\n",
    "            #full = hot_encode_top(['status_clean'],full)\n",
    "            #full = hot_encode_top(['status_clean','driverId', 'constructorId'],full)\n",
    "            full_races = full_races.append(full)\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    full_races = full_races.replace(np.nan,0)   \n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    races = full_races[cols]  \n",
    "    X = np.array(races)\n",
    "    A = ridge.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    print('alpha:',alpha)\n",
    "    print('====================')\n",
    "    \n",
    "    #hinzufügen der 'wichtigen' spalten zur späteren auswertung der vorhersagen auf dem trainingsdatensatz\n",
    "    full_races['prediction'] = A\n",
    "    full_races['total_milliseconds'] = y\n",
    "    full_races['total_minutes'] = y/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner, second, third: Sebastian Vettel , Fernando Alonso , Mark Webber\n",
      "predicted winner: Mark Webber \n",
      "\n",
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Valtteri Bottas\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Sebastian Vettel , Mark Webber\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Jenson Button , Fernando Alonso , Felipe Massa\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Daniel Ricciardo\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Jenson Button , Sebastian Vettel , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Jenson Button \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Kimi RÃŒ_ikkÃŒÂ¦nen , Romain Grosjean\n",
      "predicted winner: Michael Schumacher \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Daniel Ricciardo\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Jenson Button , Fernando Alonso\n",
      "predicted winner: Bruno Senna \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Fernando Alonso , Mark Webber\n",
      "predicted winner: Karun Chandhok \n",
      "\n",
      "winner, second, third: Fernando Alonso , Kimi RÃŒ_ikkÃŒÂ¦nen , Michael Schumacher\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Lewis Hamilton , Jenson Button\n",
      "predicted winner: Felipe Massa \n",
      "\n",
      "winner, second, third: Nico Rosberg , Valtteri Bottas , Lewis Hamilton\n",
      "predicted winner: Adrian Sutil \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Daniel Ricciardo\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Jenson Button , Fernando Alonso\n",
      "predicted winner: Jarno Trulli \n",
      "\n",
      "winner, second, third: Fernando Alonso , Sebastian Vettel , Mark Webber\n",
      "predicted winner: Jenson Button \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Lewis Hamilton , Nico Rosberg\n",
      "predicted winner: Pastor Maldonado \n",
      "\n",
      "genaue treffer: 4\n",
      "nah dran: 2\n",
      "weiter weg: 0\n"
     ]
    }
   ],
   "source": [
    "treffer = 0\n",
    "nahdran = 0\n",
    "weiterweg = 0\n",
    "for raceId in full_races.raceId.unique():\n",
    "    \n",
    "    race = full_races.where(full_races.raceId == raceId).dropna(how = 'all')\n",
    "    winner = race.where(race.podium_position == 1).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    second = race.where(race.podium_position == 2).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    third = race.where(race.podium_position == 3).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    fourth = race.where(race.podium_position == 4).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    fifth = race.where(race.podium_position == 5).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    sixth = race.where(race.podium_position == 6).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    seventh = race.where(race.podium_position == 7).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    pred_winner = race.where(race.prediction == min(race.prediction)).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    podium = [second,third]\n",
    "    seven = [fourth,fifth,sixth,seventh]\n",
    "    if pred_winner == winner:\n",
    "        treffer += 1\n",
    "    if pred_winner in podium:\n",
    "        nahdran += 1\n",
    "    if pred_winner in seven:\n",
    "        weiterweg += 1\n",
    "    print('winner, second, third:', winner,',' ,second,',' , third)\n",
    "    print('predicted winner:', pred_winner,'\\n')\n",
    "    \n",
    "print('genaue treffer:', treffer)\n",
    "print('nah dran:', nahdran)\n",
    "print('weiter weg:', weiterweg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---shuffle races---\n",
      "---training---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hwebe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "c:\\users\\hwebe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "c:\\users\\hwebe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22230.455626800063, tolerance: 100.20971595166466\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 17.299965468326885\n",
      "mae: 2.4759877864118827\n",
      "---testing---\n",
      "mse: 14.827476054289448\n",
      "mae: 2.73470304443648\n",
      "alpha: 0\n",
      "====================\n",
      "---training---\n",
      "mse: 17.8846096882247\n",
      "mae: 2.4978737299185285\n",
      "---testing---\n",
      "mse: 15.52465420092796\n",
      "mae: 2.7609354783144138\n",
      "alpha: 0.1\n",
      "====================\n",
      "---training---\n",
      "mse: 18.360667543129985\n",
      "mae: 2.515535834264905\n",
      "---testing---\n",
      "mse: 16.26206361865759\n",
      "mae: 2.7776880142138514\n",
      "alpha: 0.2\n",
      "====================\n",
      "---training---\n",
      "mse: 19.143986913412625\n",
      "mae: 2.5524060365249275\n",
      "---testing---\n",
      "mse: 17.238558385765582\n",
      "mae: 2.811279375569477\n",
      "alpha: 0.3\n",
      "====================\n",
      "---training---\n",
      "mse: 20.231202845084375\n",
      "mae: 2.6015110195439246\n",
      "---testing---\n",
      "mse: 18.47981842020273\n",
      "mae: 2.85675592969557\n",
      "alpha: 0.4\n",
      "====================\n",
      "---training---\n",
      "mse: 21.622453695948877\n",
      "mae: 2.6624840885124703\n",
      "---testing---\n",
      "mse: 19.98222329317425\n",
      "mae: 2.9188235014857593\n",
      "alpha: 0.5\n",
      "====================\n",
      "---training---\n",
      "mse: 23.322871005487816\n",
      "mae: 2.7376346918667194\n",
      "---testing---\n",
      "mse: 21.753544645280343\n",
      "mae: 2.9916066708523648\n",
      "alpha: 0.6\n",
      "====================\n",
      "---training---\n",
      "mse: 25.3324552939859\n",
      "mae: 2.823248437510403\n",
      "---testing---\n",
      "mse: 23.79378687005676\n",
      "mae: 3.0784824407476927\n",
      "alpha: 0.7\n",
      "====================\n",
      "---training---\n",
      "mse: 26.389066049232905\n",
      "mae: 2.86885851523403\n",
      "---testing---\n",
      "mse: 24.851378053025407\n",
      "mae: 3.1236040965435605\n",
      "alpha: 0.8\n",
      "====================\n",
      "---training---\n",
      "mse: 26.39398315825494\n",
      "mae: 2.8699493360678634\n",
      "---testing---\n",
      "mse: 24.857198063934852\n",
      "mae: 3.1256510024282393\n",
      "alpha: 0.9\n",
      "====================\n",
      "---training---\n",
      "mse: 26.399478750806363\n",
      "mae: 2.8711887894037362\n",
      "---testing---\n",
      "mse: 24.86358317457318\n",
      "mae: 3.1280311609794342\n",
      "alpha: 1\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "alphas = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "print('---shuffle races---')\n",
    "\n",
    "keys = list(sliced_races.keys())\n",
    "random.shuffle(keys)\n",
    "sliced_shuffled = {}\n",
    "for key in keys:\n",
    "    sliced_shuffled[key] = sliced_races[key]\n",
    "\n",
    "\n",
    "#columns werden definiert, die erst einmal nicht beachtet werden sollen\n",
    "nogo_columns = [#'grid',\n",
    "                #'race_completion',\n",
    "                'lap_position','circuitId','lap_number',\n",
    "                'podium_position', 'raceId',\n",
    "                'grandprix_name', 'driver_fullname',\n",
    "               'constructor_name', 'total_laps',\n",
    "               'status_clean', 'constructorId',\n",
    "                'total_milliseconds', 'driverId'\n",
    "               'lap_in_milliseconds','year', 'stop_binary']\n",
    "\n",
    "#testen verschiedener Generalisierungsstufen für das Regressionsmodell\n",
    "for alpha in alphas:\n",
    "\n",
    "    #definieren eines lasso Regressionsmodells\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    \n",
    "    train_break = 120\n",
    "    category_count = 13\n",
    "    counter = 0\n",
    "    \n",
    "    print('---training---')\n",
    "    full_races = pd.DataFrame()\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            break\n",
    "        else:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "            \n",
    "            full_races = full_races.append(full)\n",
    "    #full_races = full_races.replace(np.nan,0)   \n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    \n",
    "    #umrechnen in minuten\n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    races = full_races[cols]  \n",
    "    #races = races.dropna(how = 'any')\n",
    "    X = np.array(races)\n",
    "    lasso = lasso.fit(X, y)\n",
    "    A = lasso.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    full_races = pd.DataFrame()\n",
    "    print('---testing---')\n",
    "    for raceId, race in sliced_shuffled.items():\n",
    "        full = pd.DataFrame(columns = race.columns)\n",
    "        if counter == train_break:\n",
    "            last_lap = max(race.lap_number.tolist())\n",
    "            for did in race.driverId.unique():\n",
    "                stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "                race['stop_sum'] = stop_sum\n",
    "                driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "                full = full.append(driver_df)\n",
    "                \n",
    "            #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "            #temp.replace(np.nan,0,inplace = True)\n",
    "            #full = temp.copy(deep = True)\n",
    "            #for col in temp.columns:\n",
    "            #    full[col] = temp[col]\n",
    "            #full = hot_encode_top(['status_clean'],full)\n",
    "            #full = hot_encode_top(['status_clean','driverId', 'constructorId'],full)\n",
    "            full_races = full_races.append(full)\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "    #full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "    full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "    full_races = full_races.replace(np.nan,0)   \n",
    "    y = np.array(full_races['total_milliseconds']/60000)\n",
    "    cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "    races = full_races[cols]  \n",
    "    X = np.array(races)\n",
    "    A = lasso.predict(X)\n",
    "    mse = mean_squared_error(A, y)\n",
    "    mae = MAE(A,y)\n",
    "    print('mse:', mse)\n",
    "    print('mae:',mae)\n",
    "    print('alpha:',alpha)\n",
    "    print('====================')\n",
    "    \n",
    "    #hinzufügen der 'wichtigen' spalten zur späteren auswertung der vorhersagen auf dem trainingsdatensatz\n",
    "    full_races['prediction'] = A\n",
    "    full_races['total_milliseconds'] = y\n",
    "    full_races['total_minutes'] = y/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Felipe Massa\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Valtteri Bottas , Daniel Ricciardo\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Felipe Massa\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Lewis Hamilton , Valtteri Bottas\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Fernando Alonso , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Daniil Kvyat , Daniel Ricciardo\n",
      "predicted winner: Carlos Sainz \n",
      "\n",
      "winner, second, third: Jenson Button , Fernando Alonso , Felipe Massa\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Daniel Ricciardo\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Max Verstappen\n",
      "predicted winner: Sergio PÃŒÂ©rez \n",
      "\n",
      "winner, second, third: Kimi RÃŒ_ikkÃŒÂ¦nen , Fernando Alonso , Sebastian Vettel\n",
      "predicted winner: Adrian Sutil \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Kimi RÃŒ_ikkÃŒÂ¦nen , Sebastian Vettel\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Nico Rosberg , Daniel Ricciardo , Lewis Hamilton\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Valtteri Bottas , Sebastian Vettel , Daniel Ricciardo\n",
      "predicted winner: Valtteri Bottas \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Sebastian Vettel , Fernando Alonso\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Fernando Alonso , Mark Webber\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Jenson Button , Fernando Alonso , Sebastian Vettel\n",
      "predicted winner: Fernando Alonso \n",
      "\n",
      "genaue treffer: 9\n",
      "nah dran: 4\n",
      "weiter weg: 2\n"
     ]
    }
   ],
   "source": [
    "treffer = 0\n",
    "nahdran = 0\n",
    "weiterweg = 0\n",
    "for raceId in full_races.raceId.unique():\n",
    "    \n",
    "    race = full_races.where(full_races.raceId == raceId).dropna(how = 'all')\n",
    "    winner = race.where(race.podium_position == 1).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    second = race.where(race.podium_position == 2).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    third = race.where(race.podium_position == 3).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    fourth = race.where(race.podium_position == 4).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    fifth = race.where(race.podium_position == 5).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    sixth = race.where(race.podium_position == 6).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    seventh = race.where(race.podium_position == 7).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    pred_winner = race.where(race.prediction == min(race.prediction)).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    podium = [second,third]\n",
    "    seven = [fourth,fifth,sixth,seventh]\n",
    "    if pred_winner == winner:\n",
    "        treffer += 1\n",
    "    if pred_winner in podium:\n",
    "        nahdran += 1\n",
    "    if pred_winner in seven:\n",
    "        weiterweg += 1\n",
    "    print('winner, second, third:', winner,',' ,second,',' , third)\n",
    "    print('predicted winner:', pred_winner,'\\n')\n",
    "    \n",
    "print('genaue treffer:', treffer)\n",
    "print('nah dran:', nahdran)\n",
    "print('weiter weg:', weiterweg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
