{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as sqldf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys,os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPEZIELLE VERSION, nicht kopieren!\n",
    "def hot_encode_top_ohnelapped (column, df, feat_count = 10):\n",
    "    '''\n",
    "    hot one encoding, limitiert auf die feat_count häufigsten features\n",
    "    eines nominalen features um zu Hohe dimensionen zu vermeiden\n",
    "    \n",
    "    column: liste mit einem oder mehr Spaltennamen, die hot encoded werden sollen\n",
    "    df: dataframe der die Datenbasis darstellt\n",
    "    feat_count: Anzahl Spalten die für jede Spalte encoded werden\n",
    "    '''\n",
    "    df_ = df.copy(deep = True)\n",
    "    \n",
    "    for col in column:\n",
    "        \n",
    "        \n",
    "        #nur die häufigsten feat_count Featues werden encoded\n",
    "        encode_features = [x for x in df_[col].value_counts(ascending = False).head(feat_count).index]\n",
    "        if col == 'status_clean':\n",
    "            #encode_features = ['lapped', 'Finished', 'DNF']\n",
    "            encode_features = ['Finished', 'DNF']\n",
    "        for feature in encode_features:\n",
    "            col_feature = col + '_'+str(feature)\n",
    "            if col == 'status_clean' and feature == 'DNF':\n",
    "                df_[col_feature] = df_.where(np.logical_or(df_[col] == feature,df_[col] == 'lapped'), other = 0)[col]\n",
    "                df_[col_feature].replace(feature, 1, inplace = True)\n",
    "                df_[col_feature].replace('lapped', 1, inplace = True)\n",
    "            else:\n",
    "                #dort wo feature nicht dem encode feature entspricht wird eine 0 gesetzt\n",
    "                df_[col_feature] = df_.where(df_[col] == feature, other = 0)[col]\n",
    "                #encode feature selbst wird in dataframe durch eine 1 ersetzt\n",
    "                df_[col_feature].replace(feature, 1, inplace = True)\n",
    "            \n",
    "        \n",
    "        #löschen der nun \"bereinigten\" Spalte\n",
    "        del df_[col]\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_top (column, df, feat_count = 10):\n",
    "    '''\n",
    "    hot one encoding, limitiert auf die feat_count häufigsten features\n",
    "    eines nominalen features um zu Hohe dimensionen zu vermeiden\n",
    "    \n",
    "    column: liste mit einem oder mehr Spaltennamen, die hot encoded werden sollen\n",
    "    df: dataframe der die Datenbasis darstellt\n",
    "    feat_count: Anzahl Spalten die für jede Spalte encoded werden\n",
    "    '''\n",
    "    df_ = df.copy(deep = True)\n",
    "    \n",
    "    for col in column:\n",
    "        \n",
    "        \n",
    "        #nur die häufigsten feat_count Featues werden encoded\n",
    "        encode_features = [x for x in df_[col].value_counts(ascending = False).head(feat_count).index]\n",
    "        if col == 'status_clean':\n",
    "            #encode_features = ['lapped', 'Finished', 'DNF']\n",
    "            encode_features = ['Finished', 'DNF']\n",
    "        for feature in encode_features:\n",
    "            col_feature = col + '_'+str(feature)\n",
    "            \n",
    "            #dort wo feature nicht dem encode feature entspricht wird eine 0 gesetzt\n",
    "            df_[col_feature] = df_.where(df_[col] == feature, other = 0)[col]\n",
    "            #encode feature selbst wird in dataframe durch eine 1 ersetzt\n",
    "            df_[col_feature].replace(feature, 1, inplace = True)\n",
    "            \n",
    "        \n",
    "        #löschen der nun \"bereinigten\" Spalte\n",
    "        del df_[col]\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einlesen der sliced Dateien erfolgreich\n",
      "Einlesen der split Dateien erfolgreich\n"
     ]
    }
   ],
   "source": [
    "rain_id = [847,861,879,910,914,934,942,953,957,967,970,982]\n",
    "if os.path.exists('sliced_data70'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/sliced_data70'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    sliced_races = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('sliced_data70/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('sliced_data70/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        df[\"rain\"] = 0\n",
    "        if list(df[\"raceId\"])[0] in rain_id:\n",
    "            df[\"rain\"] = 1\n",
    "        sliced_races[f] = df\n",
    "    print('Einlesen der sliced Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')\n",
    "    \n",
    "if os.path.exists('split_data'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/split_data'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    split_by_race = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        split_by_race[f] = df\n",
    "    print('Einlesen der split Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einlesen der sliced Dateien erfolgreich\n",
      "Einlesen der split Dateien erfolgreich\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('sliced_data70'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/sliced_data70'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    sliced_races = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('sliced_data70/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('sliced_data70/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        sliced_races[f] = df\n",
    "    print('Einlesen der sliced Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')\n",
    "    \n",
    "if os.path.exists('split_data'):\n",
    "    csv_filenames = []\n",
    "    #auslesen aller csv file dateinamen aus formula 1 datensatz und abspeichern in liste\n",
    "    for filename in os.listdir(os.getcwd()+'/split_data'):\n",
    "        typ = filename.split('.')[-1]\n",
    "        name = filename.split('.')[0]\n",
    "        if typ == 'csv':\n",
    "            csv_filenames.append(filename)\n",
    "    split_by_race = {}\n",
    "    #einlesen und abspeichern als dataframe aller dateien\n",
    "    for file in csv_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'python', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "        except Exception as e:\n",
    "            df = pd.read_csv('split_data/'+file, engine = 'c', sep = ';', decimal = '.')\n",
    "            del df['Unnamed: 0']\n",
    "            print(e)\n",
    "        #print(df.head())\n",
    "        f = int(file.split('_')[-1].split('.')[0])\n",
    "        split_by_race[f] = df\n",
    "    print('Einlesen der split Dateien erfolgreich')\n",
    "else:\n",
    "    print('Dateien können nicht eingelesen werden, da kein entsprechendes Verzeichnis existiert!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---training---\n",
      "mse: 17.29996546832689\n",
      "---testing---\n",
      "mse: 12.965065493605882\n"
     ]
    }
   ],
   "source": [
    "keys = list(sliced_races.keys())\n",
    "random.shuffle(keys)\n",
    "sliced_shuffled = {}\n",
    "for key in keys:\n",
    "    sliced_shuffled[key] = sliced_races[key]\n",
    "\n",
    "\n",
    "#columns werden definiert, die erst einmal nicht beachtet werden sollen\n",
    "nogo_columns = [#'grid',\n",
    "                #'race_completion',\n",
    "                'lap_position','circuitId','lap_number',\n",
    "                'podium_position', 'raceId',\n",
    "                'grandprix_name', 'driver_fullname',\n",
    "               'constructor_name', 'total_laps',\n",
    "               'status_clean', 'constructorId',\n",
    "                'total_milliseconds', 'driverId'\n",
    "               'lap_in_milliseconds','year', 'stop_binary']\n",
    "\n",
    "#definieren eines linearen Regressionsmodells\n",
    "reg = LinearRegression()\n",
    "\n",
    "train_break = 120\n",
    "category_count = 13\n",
    "counter = 0\n",
    "\n",
    "print('---training---')\n",
    "full_races = pd.DataFrame()\n",
    "for raceId, race in sliced_shuffled.items():\n",
    "    full = pd.DataFrame(columns = race.columns)\n",
    "    if counter == train_break:\n",
    "        break\n",
    "    else:\n",
    "        last_lap = max(race.lap_number.tolist())\n",
    "        for did in race.driverId.unique():\n",
    "            stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "            race['stop_sum'] = stop_sum\n",
    "            driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "            full = full.append(driver_df)\n",
    "        #for elem in full['driverId'].unique():\n",
    "        #    full[str(elem)] = full['driverId'] == elem\n",
    "        #for elem in full['constructorId'].unique():\n",
    "        #    full[str(elem)] = full['constructorId'] == elem\n",
    "        #for c in ['driverId','constructorId']:\n",
    "        #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "        #temp.replace(np.nan,0,inplace = True)\n",
    "        #full = temp.copy(deep = True)\n",
    "        ##for col in temp.columns:\n",
    "        #    full[col] = temp[col]\n",
    "        full_races = full_races.append(full)\n",
    "#full_races = full_races.replace(np.nan,0)   \n",
    "#full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "\n",
    "#umrechnen in minuten\n",
    "y = np.array(full_races['total_milliseconds']/60000)\n",
    "races = full_races[cols]  \n",
    "#races = races.dropna(how = 'any')\n",
    "X = np.array(races)\n",
    "reg = reg.fit(X, y)\n",
    "A = reg.predict(X)\n",
    "mse = mean_squared_error(A, y)\n",
    "print('mse:', mse)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "full_races = pd.DataFrame()\n",
    "print('---testing---')\n",
    "for raceId, race in sliced_shuffled.items():\n",
    "    full = pd.DataFrame(columns = race.columns)\n",
    "    if counter == train_break:\n",
    "        last_lap = max(race.lap_number.tolist())\n",
    "        for did in race.driverId.unique():\n",
    "            stop_sum = np.sum(race.where(race.driverId == did).dropna(how='all')['stop_binary'])\n",
    "            race['stop_sum'] = stop_sum\n",
    "            driver_df = race.where(np.logical_and(race.lap_number == last_lap, race.driverId == did)).dropna(how = 'all')\n",
    "            full = full.append(driver_df)\n",
    "            \n",
    "        #temp = pd.get_dummies(data = full, columns = ['driverId','constructorId'], drop_first = True)\n",
    "        #temp.replace(np.nan,0,inplace = True)\n",
    "        #full = temp.copy(deep = True)\n",
    "        #for col in temp.columns:\n",
    "        #    full[col] = temp[col]\n",
    "        #full = hot_encode_top(['status_clean'],full)\n",
    "        #full = hot_encode_top(['status_clean','driverId', 'constructorId'],full)\n",
    "        full_races = full_races.append(full)\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "#full_races = hot_encode_top(['status_clean','driverId', 'constructorId'],full_races,15)\n",
    "full_races = hot_encode_top(['status_clean','driverId'],full_races,category_count)\n",
    "full_races = full_races.replace(np.nan,0)   \n",
    "y = np.array(full_races['total_milliseconds']/60000)\n",
    "cols = [col for col in full_races.columns if col not in nogo_columns] \n",
    "races = full_races[cols]  \n",
    "X = np.array(races)\n",
    "A = reg.predict(X)\n",
    "mse = mean_squared_error(A, y)\n",
    "print('mse:', mse)\n",
    "\n",
    "#hinzufügen der 'wichtigen' spalten zur späteren auswertung der vorhersagen auf dem trainingsdatensatz\n",
    "full_races['prediction'] = A\n",
    "full_races['total_milliseconds'] = y\n",
    "full_races['total_minutes'] = y/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner, second, third: Lewis Hamilton , Sebastian Vettel , Sergio PÃŒÂ©rez\n",
      "predicted winner: Valtteri Bottas \n",
      "\n",
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Sebastian Vettel\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Sebastian Vettel\n",
      "predicted winner: Kimi RÃŒ_ikkÃŒÂ¦nen \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Jenson Button , Fernando Alonso\n",
      "predicted winner: Fernando Alonso \n",
      "\n",
      "winner, second, third: Nico Rosberg , Sebastian Vettel , Lewis Hamilton\n",
      "predicted winner: Max Verstappen \n",
      "\n",
      "winner, second, third: Nico Rosberg , Lewis Hamilton , Valtteri Bottas\n",
      "predicted winner: Sebastian Vettel \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Nico Rosberg , Fernando Alonso\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Valtteri Bottas , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Lewis Hamilton \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Fernando Alonso , Lewis Hamilton\n",
      "predicted winner: Esteban GutiÃŒÂ©rrez \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Daniel Ricciardo , Kimi RÃŒ_ikkÃŒÂ¦nen\n",
      "predicted winner: Romain Grosjean \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Felipe Massa , Kamui Kobayashi\n",
      "predicted winner: Charles Pic \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Daniel Ricciardo , Valtteri Bottas\n",
      "predicted winner: Nico HÃŒ_lkenberg \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Sebastian Vettel , Valtteri Bottas\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Lewis Hamilton , Valtteri Bottas\n",
      "predicted winner: Fernando Alonso \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Fernando Alonso , Jenson Button\n",
      "predicted winner: Daniel Ricciardo \n",
      "\n",
      "winner, second, third: Lewis Hamilton , Kimi RÃŒ_ikkÃŒÂ¦nen , Nico Rosberg\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "winner, second, third: Sebastian Vettel , Mark Webber , Nico Rosberg\n",
      "predicted winner: Nico Rosberg \n",
      "\n",
      "genaue treffer: 2\n",
      "nah dran: 4\n",
      "weiter weg: 1\n"
     ]
    }
   ],
   "source": [
    "treffer = 0\n",
    "nahdran = 0\n",
    "weiterweg = 0\n",
    "for raceId in full_races.raceId.unique():\n",
    "    \n",
    "    race = full_races.where(full_races.raceId == raceId).dropna(how = 'all')\n",
    "    winner = race.where(race.podium_position == 1).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    second = race.where(race.podium_position == 2).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    third = race.where(race.podium_position == 3).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    fourth = race.where(race.podium_position == 4).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    fifth = race.where(race.podium_position == 5).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    sixth = race.where(race.podium_position == 6).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    seventh = race.where(race.podium_position == 7).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    pred_winner = race.where(race.prediction == min(race.prediction)).dropna(how = 'all')['driver_fullname'].tolist()[0]\n",
    "    \n",
    "    podium = [second,third]\n",
    "    seven = [fourth,fifth,sixth,seventh]\n",
    "    if pred_winner == winner:\n",
    "        treffer += 1\n",
    "    if pred_winner in podium:\n",
    "        nahdran += 1\n",
    "    if pred_winner in seven:\n",
    "        weiterweg += 1\n",
    "    print('winner, second, third:', winner,',' ,second,',' , third)\n",
    "    print('predicted winner:', pred_winner,'\\n')\n",
    "    \n",
    "print('genaue treffer:', treffer)\n",
    "print('nah dran:', nahdran)\n",
    "print('weiter weg:', weiterweg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lap_in_milliseconds</th>\n",
       "      <th>race_completion</th>\n",
       "      <th>grid</th>\n",
       "      <th>form</th>\n",
       "      <th>sum_milliseconds_pro_lap</th>\n",
       "      <th>rain</th>\n",
       "      <th>stop_sum</th>\n",
       "      <th>status_clean_Finished</th>\n",
       "      <th>status_clean_DNF</th>\n",
       "      <th>driverId_815.0</th>\n",
       "      <th>...</th>\n",
       "      <th>driverId_1.0</th>\n",
       "      <th>driverId_817.0</th>\n",
       "      <th>driverId_20.0</th>\n",
       "      <th>driverId_13.0</th>\n",
       "      <th>driverId_3.0</th>\n",
       "      <th>driverId_154.0</th>\n",
       "      <th>driverId_4.0</th>\n",
       "      <th>driverId_18.0</th>\n",
       "      <th>driverId_822.0</th>\n",
       "      <th>driverId_814.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>81230.0</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>3812800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>84766.0</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>3813516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>81048.0</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>3798965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>81987.0</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>3840887.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>97800.0</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3904590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lap_in_milliseconds  race_completion  grid   form  \\\n",
       "45               81230.0         0.686567  13.0  15.00   \n",
       "91               84766.0         0.686567  12.0  12.75   \n",
       "173              81048.0         0.686567   7.0   9.50   \n",
       "219              81987.0         0.686567  16.0  15.00   \n",
       "265              97800.0         0.686567  14.0  15.25   \n",
       "\n",
       "     sum_milliseconds_pro_lap  rain  stop_sum  status_clean_Finished  \\\n",
       "45                  3812800.0   0.0       2.0                      0   \n",
       "91                  3813516.0   0.0       3.0                      0   \n",
       "173                 3798965.0   0.0       2.0                      0   \n",
       "219                 3840887.0   0.0       2.0                      0   \n",
       "265                 3904590.0   0.0       3.0                      0   \n",
       "\n",
       "     status_clean_DNF  driverId_815.0  ...  driverId_1.0  driverId_817.0  \\\n",
       "45                  0             0.0  ...           0.0             0.0   \n",
       "91                  0             0.0  ...           0.0             0.0   \n",
       "173                 0             0.0  ...           0.0             0.0   \n",
       "219                 0             0.0  ...           0.0             0.0   \n",
       "265                 0             0.0  ...           0.0             0.0   \n",
       "\n",
       "     driverId_20.0  driverId_13.0  driverId_3.0  driverId_154.0  driverId_4.0  \\\n",
       "45             0.0            0.0           0.0             0.0           1.0   \n",
       "91             0.0            0.0           0.0             0.0           0.0   \n",
       "173            0.0            0.0           0.0             0.0           0.0   \n",
       "219            0.0            0.0           0.0             0.0           0.0   \n",
       "265            0.0            0.0           0.0             0.0           0.0   \n",
       "\n",
       "     driverId_18.0  driverId_822.0  driverId_814.0  \n",
       "45             0.0             0.0             0.0  \n",
       "91             1.0             0.0             0.0  \n",
       "173            0.0             1.0             0.0  \n",
       "219            0.0             0.0             0.0  \n",
       "265            0.0             0.0             0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lap_in_milliseconds', 'race_completion', 'grid', 'form',\n",
       "       'sum_milliseconds_pro_lap', 'rain', 'stop_sum', 'status_clean_Finished',\n",
       "       'status_clean_DNF', 'driverId_815.0', 'driverId_807.0', 'driverId_8.0',\n",
       "       'driverId_1.0', 'driverId_817.0', 'driverId_20.0', 'driverId_13.0',\n",
       "       'driverId_3.0', 'driverId_154.0', 'driverId_4.0', 'driverId_18.0',\n",
       "       'driverId_822.0', 'driverId_814.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
